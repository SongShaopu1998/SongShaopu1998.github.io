---
layout:		post
title:		CMU 15-418
date:		2023-03-15
author:		shaopu
header-img:	img/code.png
catalog:	true

tags:
   - C++
   - Parallel Computing
---

本文写在`61C`的并行计算部分后。

## Lecture 2: A Modern Multi-Core Processor

这节课的内容可以大致分成两部分。首先讲述了如何提高峰值并行效率，其次讲解了如何缓解/减少由于内存访问带来的并行效率下降的问题。

### Coherent execution

`SIMD`指令与`multi-core`不同，`SIMD`指令运行的指令一定都是一样的（只是输入不一样），但多核可以并行运行完全不同的指令，所以在`SIMD`遇到分支时就会产生一些问题。

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-055606.png" alt="image-20230315225606232" style="zoom: 33%;" />

如果循环体内部含有分支语句，意味着对于不同的输入，并不能够在一开始就确定走`if`还是`else`，所以`SIMD`指令不能直接利用。此时我们可以将指令重排列，从而将走`if`的语句安排在一起，走`else`的语句安排在一起。而如果不想重排指令，我们就要使用如上图所示的方法，即分别对`if`和`else`做一次`SIMD`运算，然后根据输入设定`mask`，来决定到底将哪些对应的计算结果输出。我们能够预想到的最坏情况发生在两个分支的代码复杂度相差较大时，并且此时绝大多数数据都走向了复杂度较小的分支。那么因为对于两个分支都要进行一遍`SIMD`运算，就会导致我们在无用的运算结果上花费了大量时间。换句话说，`SIMD`的高效运算取决于避免上述情况的发生，我们将这种先决条件称为`Coherent execution`。

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-060510.png" alt="image-20230315230510091" style="zoom:33%;" />

### summary of parallel execution

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-061117.png" alt="image-20230315231117483" style="zoom:33%;" />

我们有三种并行运算的思路：

- **Multi-core** (thread-level)
- **SIMD** (instruction level)
- **Superscalar**

> 其中`Superscalar`着重在**一个**内核中对**一个**`instruction stream`执行多个独立指令的并行运算

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-061147.png" alt="image-20230315231144290" style="zoom:33%;" />

需要注意的是，`SIMD`指令是比“多线程”更加底层的技法，他的指令执行由计算单元完成，只需要一个线程就可以执行，并非需要多个线程来并行`SIMD`的向量化计算过程。

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-102929.png" alt="image-20230316032928587" style="zoom:50%;" />

### Lantency & Bandwith

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-092422.png" alt="image-20230316022422678" style="zoom:33%;" />

越高的内存带宽不等价于更高的内存延迟：虽然一次性能够和内存交互更多的数据，但一次存取数据（`load/store`）需要花费的时间可能更长。

### Latency

有两种手段处理延迟：

- reduce latency
- hide latency

降低延迟的方法包括**使用多级缓存**，隐藏延迟的方法包括：

- prefetching
- multi-threading (interleave processing of multiple threads **on the same core** to hide stalls)

#### Multithreading

##### 如何理解硬件多线程

硬件多线程，顾名思义，是需要硬件支持的多线程（当然也需要OS的配合来实现），在程序中使用的“多线程”是软件多线程，我们可以把硬件多线程理解为软件多线程的实体（但这不意味着两者具有一对一的映射关系）。硬件级别多线程设计的存在能够让系统的线程执行效率更高：处理器会为线程分配对应的`execution context`区块，并**由处理器决定当前执行哪个线程，而非操作系统**。（当然最后硬件多线程的调度也要映射到OS层面的调度，否则没有意义）

##### 多线程的trade-off

当使用多线程时，存在几个trade-off: 

首先是当`interleave`多个线程时，单个线程的执行时间变长了，但是系统整体的吞吐量提高了：

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-095901.png" alt="image-20230316025901256" style="zoom:33%;" />

其次是当拥有较多数量的线程时，意味着系统有较强的`hiding latency`的能力；当可分配的线程数量较少时，单独的线程会拥有更大的`work set`，也就意味着`cache`中可以分配给每个线程的内存更多了。

##### 多线程设计模式分类

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-21-002511.png" alt="image-20230320172511197" style="zoom: 33%;" />

多线程的设计方法可以被分成两类：

- **Interleaved Multi-threading (Temporal Multi-threading)**

这种多线程模式意味着在每一个时钟周期内，每一个核只执行一个线程，这种设计模式还可以划分成两种子类：

1. Coarse-grained Multi-threading

在这种模式下，每个线程会一直执行到发生`costly stall`的时候（比如`2nd cache miss`），对于`shortly stall`并不关心。（每个线程需要独立的`PC`, `register file`等硬件支持）

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-21-002739.png" alt="image-20230320172739063" style="zoom:33%;" />

2. Fine-grained Multi-threading

在这种模式下，多个线程使用`robin-round`等方法`interleave`各自的`instruction`，当遇到发生`stall`的线程则会直接跳过。在这种模式下，不会单单等到某一个线程发生`costly stall`时处理器才让另一个线程来接管他。（每个线程需要独立的`PC`, `register file`等硬件支持）

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-21-002806.png" alt="image-20230320172806526" style="zoom:33%;" />

- **Simultaneous Multi-threading (SMT)**

Intel的**Hyper-threading**就是基于`SMT`的典型设计之一。在该模式下，一个物理核被分为多个逻辑核，这意味着在同一个时钟信号内，系统允许处理器同时执行多个线程。（每个线程需要独立的`PC`, `register file`等硬件支持）

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-21-002831.png" alt="image-20230320172831208" style="zoom:33%;" />

在`SMT`模式下的多线程因为要在同一时刻，在同一个内核中执行多个指令，所以可以理解为一种基于`Superscalar`设计的扩展。但`SMT`和`Superscalar`并不一样，`Superscalar`机制由于不具备独立的`Execution Context`，所以只能从一个`instruction stream`中选择独立指令，但是`SMT`允许处理器从多个`instruction stream`中选择独立指令（这也是`Hyper-threading`想法产生的原因，即想要从同一个指令流中选择多个独立的指令并不容易，所以Intel想要借助多个线程来从多个指令流中选择独立指令）。这也意味着`SMT`和`Superscalar`可以同时使用（虽然Intel的`Superscalar`机制实际上是用来帮助实现`Hyper-threading`了），以`GTX 680`为例（`Warp`在这里表示`instruction stream`）：

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-21-010736.png" alt="image-20230320180736901" style="zoom:50%;" />

需要注意的是，`SMT`具备从多个`instruction stream`中选择独立指令的能力并不意味着它一定要这么做，处理器会找到能够利用核心内所有执行单元的最佳方案，这种方案可能会从同一个线程中选择多个指令（this thread has sufficient ILP）同时执行，这会让处理器表现的像`interleaved multi-threading`一样。

### CPU & GPU

- CPU

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-100623.png" alt="image-20230316030623713" style="zoom:33%;" />

> 64=16*4
>
> 512=64*8

- CPU vs. GPU

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-101020.png" alt="image-20230316031020240" style="zoom:33%;" />

上图表明，CPU会利用更大的缓存来降低延迟，同时使用指令预抓取的方法隐藏延迟。而GPU则将更多的资源集中在了多线程上，它只配备了很小的缓存。进一步的计算可发现，想要完全利用GPU自身提供的多线程/SIMD/多核机制时很难的，换句话说我们需要花费很大的代价才能让GPU keep busy，其所需的`bandwith`远超上图的`177GB/sec`（一秒钟内转移多少数据才能让下一秒的GPU一直干活，如此循环往复）。这种现象的原因被称为**bandwith limited**。