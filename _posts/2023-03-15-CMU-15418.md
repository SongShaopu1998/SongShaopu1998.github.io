---
layout:		post
title:		CMU 15-418
date:		2023-03-15
author:		shaopu
header-img:	img/code.png
catalog:	true

tags:
   - C++
   - Parallel Computing
---

本文写在`61C`的并行计算部分后。

## Lecture 2: A Modern Multi-Core Processor

这节课的内容可以大致分成两部分。首先讲述了如何提高峰值并行效率，其次讲解了如何缓解/减少由于内存访问带来的并行效率下降的问题。

### Coherent execution

`SIMD`指令与`multi-core`不同，`SIMD`指令运行的指令一定都是一样的（只是输入不一样），但多核可以并行运行完全不同的指令，所以在`SIMD`遇到分支时就会产生一些问题。

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-055606.png" alt="image-20230315225606232" style="zoom: 33%;" />

如果循环体内部含有分支语句，意味着对于不同的输入，并不能够在一开始就确定走`if`还是`else`，所以`SIMD`指令不能直接利用。此时我们可以将指令重排列，从而将走`if`的语句安排在一起，走`else`的语句安排在一起。而如果不想重排指令，我们就要使用如上图所示的方法，即分别对`if`和`else`做一次`SIMD`运算，然后根据输入设定`mask`，来决定到底将哪些对应的计算结果输出。我们能够预想到的最坏情况发生在两个分支的代码复杂度相差较大时，因为对于两个分支都要进行一遍`SIMD`运算，可能导致我们在无用的运算结果上花费了大量时间。换句话说，`SIMD`的高效运算取决于避免上述情况的发生，我们将这种先决条件称为`Coherent execution`。

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-060510.png" alt="image-20230315230510091" style="zoom:33%;" />

### summary of parallel execution

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-061117.png" alt="image-20230315231117483" style="zoom:33%;" />

我们有三种并行运算的思路：

- **Multi-core** (thread-level)
- **SIMD** (instruction level)
- **Superscalar**

> 其中`Superscalar`着重在**一个**内核中对**一个**`instruction stream`执行多个独立指令的并行运算

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-061147.png" alt="image-20230315231144290" style="zoom:33%;" />

需要注意的是，`SIMD`指令是比“多线程”更加底层的技法，他的指令执行由计算单元完成，只需要一个线程就可以执行，并非需要多个线程来并行`SIMD`的向量化计算过程。

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-102929.png" alt="image-20230316032928587" style="zoom:50%;" />

### Lantency & Bandwith

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-092422.png" alt="image-20230316022422678" style="zoom:33%;" />

越高的内存带宽不等价于更高的内存延迟：虽然一次性能够和内存交互更多的数据，但一次存取数据（`load/store`）需要花费的时间可能更长。

### Latency

有两种手段处理延迟：

- reduce latency
- hide latency

降低延迟的方法包括使用多级缓存，隐藏延迟的方法包括：

- prefetching
- multi-threading (interleave processing of multiple threads **on the same core** to hide stalls)

当使用多线程时，存在几个trade-off:

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-095901.png" alt="image-20230316025901256" style="zoom:33%;" />

其次是一个内核中线程数量的影响：当拥有较多数量的线程时，意味着系统有较强的`hiding latency`的能力；当可分配的线程数量较少时，单独的线程会拥有更大的`work set`.

### CPU & GPU

- CPU

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-100623.png" alt="image-20230316030623713" style="zoom:33%;" />

> 64=16*4
>
> 512=64*8

- CPU vs. GPU

<img src="https://shaopu-blog.oss-cn-beijing.aliyuncs.com/img/2023-03-16-101020.png" alt="image-20230316031020240" style="zoom:33%;" />

上图表明，CPU会利用更大的缓存来降低延迟，同时使用指令预抓取的方法隐藏延迟。而GPU则将更多的资源集中在了多线程上，它只配备了很小的缓存。进一步的计算可发现，想要完全利用GPU自身提供的多线程/SIMD/多核机制时很难的，换句话说我们需要花费很大的代价才能让GPU keep busy，其所需的`bandwith`远超上图的`177GB/sec`（一秒钟内转移多少数据才能让下一秒的GPU一直干活，如此循环往复）。这种现象的原因被称为**bandwith limited**。